{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Wiktoria Szymańska 140790\n",
        "\n",
        "##### Laboratorium KCK\n",
        "\n",
        "### **Projekt**: Rozpoznawanie płci po głosie.\n",
        "\n",
        "\n",
        "Celem projektu jest stworzenie prostego systemu do rozpoznawania płci na podstawie próbek dźwiękowych głosu. System wykorzystuje analizę częstotliwości fundamentalnych głosu, aby określić, czy głos należy do mężczyzny czy kobiety.\n"
      ],
      "metadata": {
        "id": "CEbH14yzGVqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dane wejściowe:\n",
        "\n",
        "Krótkie nagrania w formacie WAV. Do celów testowych przygotowano niewielki zbiór nagrań, które umieszczono w folderze *'input_voice_recognition'*. Zawiera on po 7 nagrań z głosami męskimi i żeńskimi umieszczonymi w odpowiednich podkatalogach: *'male'* i *'female'*.\n",
        "\n",
        "Źródło danych do testowania:\n",
        "\n",
        "https://commons.wikimedia.org/wiki/Category:Audio_files_of_males_speaking_English\n",
        "\n",
        "https://commons.wikimedia.org/wiki/Category:Audio_files_of_females_speaking_English\n"
      ],
      "metadata": {
        "id": "o7lNdQ58Z4dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja:\n",
        "\n",
        "Funkcja *analyze_voice* analizuje dźwiękowe pliki WAV, wyznaczając częstotliwości fundamentalne głosu. Wykorzystuje do tego operację FFT (Fast Fourier Transform) w celu przekształcenia sygnału dźwiękowego z dziedziny czasu do dziedziny częstotliwości.\n",
        "\n",
        "Na podstawie średniej częstotliwości fundamentalnej obliczonej dla danej próbki dźwiękowej, program decyduje, czy głos należy do mężczyzny czy kobiety. Wartość 165 Hz jest używana jako próg decyzyjny - głosy o średniej częstotliwości poniżej tego progu są rozpoznawane jako męskie, a powyżej jako żeńskie."
      ],
      "metadata": {
        "id": "azlsFegwIZuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import wave"
      ],
      "metadata": {
        "id": "q6lj2P77fnLw"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_voice(filename):\n",
        "    with wave.open(filename, 'rb') as wav:\n",
        "        frame_rate = wav.getframerate()\n",
        "        n_frames = wav.getnframes()\n",
        "        n_channels = wav.getnchannels()\n",
        "        sample_width = wav.getsampwidth()\n",
        "\n",
        "        frames = wav.readframes(n_frames)\n",
        "\n",
        "        if sample_width == 1:\n",
        "            dtype = np.int8\n",
        "        elif sample_width == 2:\n",
        "            dtype = np.int16\n",
        "        else:\n",
        "            print(\"Unsupported sample width.\")\n",
        "            return None\n",
        "\n",
        "        # decode frames to samples (multiple channels)\n",
        "        samples = np.frombuffer(frames, dtype=dtype)\n",
        "        samples = samples.reshape(-1, n_channels)\n",
        "\n",
        "        # FFT\n",
        "        spectrum = np.fft.fft(samples, axis=0)\n",
        "        power_spectrum = np.abs(spectrum) ** 2\n",
        "\n",
        "        # frequencies corresponding to each sample in the spectrum\n",
        "        frequencies = np.fft.fftfreq(len(power_spectrum), d=1/frame_rate)\n",
        "\n",
        "        # peak frequency for each channel (within range 50 - 300 Hz)\n",
        "        min_freq_index = np.argmax(frequencies > 50)\n",
        "        max_freq_index = np.argmax(frequencies > 300)\n",
        "        max_power_indices = np.argmax(power_spectrum[min_freq_index:max_freq_index], axis=0)\n",
        "        fundamental_frequencies = frequencies[min_freq_index:max_freq_index][max_power_indices]\n",
        "\n",
        "        # determine gender\n",
        "        mean_fundamental_frequency = np.mean(fundamental_frequencies)\n",
        "        gender = 'male' if mean_fundamental_frequency < 165 else 'female'\n",
        "\n",
        "        return gender\n"
      ],
      "metadata": {
        "id": "id9AcxRRZ8_l"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_folder(folder_path):\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    for subdir, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                file_path = os.path.join(subdir, file)\n",
        "                # Prawdziwa płeć na podstawie nazwy podkatalogu\n",
        "                true_gender = os.path.basename(subdir)\n",
        "                gender = analyze_voice(file_path)\n",
        "                correct = 'correctly' if true_gender == gender else 'incorrectly'\n",
        "                if correct == 'correctly':\n",
        "                    correct_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "                # kolor czerwony lub zielony\n",
        "                color = '\\033[92m' if correct == 'correctly' else '\\033[91m'\n",
        "                print(\"File: {}\\t Gender: {}\\t Recognized: {}{}{}\".format(file, gender, color, correct, '\\033[0m'))\n",
        "\n",
        "    accuracy = (correct_count / total_count) * 100\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "\n",
        "input_folder = 'input_voice_recognition'\n",
        "process_folder(input_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO13bdoCc9LF",
        "outputId": "9ba184f3-6a5e-4132-a542-3db45544f820"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: Ann_Daniels_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Mary_Mackey_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Joy_Buolamwini_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Emma_Freud_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Lady_Cobham_voice.wav\t Gender: male\t Recognized: \u001b[91mincorrectly\u001b[0m\n",
            "File: Heather_Ford_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Sarah_Outen_voice.wav\t Gender: female\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: sample.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Antony_John_Williams_voice.wav\t Gender: female\t Recognized: \u001b[91mincorrectly\u001b[0m\n",
            "File: Keri_Davies_voice.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Michael_Sheen_voice.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Brian_Dunning_voice.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Dougie_Brown_voice.wav\t Gender: female\t Recognized: \u001b[91mincorrectly\u001b[0m\n",
            "File: Chris_Woakes_voice.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "File: Piers_Gibbon_voice.wav\t Gender: male\t Recognized: \u001b[92mcorrectly\u001b[0m\n",
            "Accuracy: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyniki:\n",
        "\n",
        "W oparciu o zestaw testowy danych dźwiękowych uzyskano dokładność rozpoznania płci na poziomie 80%.\n",
        "Metoda oparta na FFT jest prosta w implementacji, ale nie gwarantuje pełnej dokładności w rozpoznawaniu płci, co wynika z braku uwzględnienia innych istotnych cech głosu oraz indywidualnych różnic między poszczególnymi głosami."
      ],
      "metadata": {
        "id": "HNxAQfM6Ipct"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQgMQuz0fpap"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(analyze_voice('input_voice_recognition/male/sample.wav'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXTCBFChpdD4",
        "outputId": "54da7684-1743-41ea-98c6-a46bb060cac8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbCF0dFcqKNz"
      },
      "execution_count": 129,
      "outputs": []
    }
  ]
}